{
  "name": "astro-ai-robots-txt-docs",
  "version": "0.0.1",
  "license": "MIT",
  "description": "Block AI scrapers in the `robots.txt` for your Astro site",
  "author": "delucis",
  "type": "module",
  "scripts": {
    "dev": "astro dev",
    "start": "astro dev",
    "build": "astro build",
    "preview": "astro preview",
    "astro": "astro"
  },
  "dependencies": {
    "@astrojs/starlight": "^0.32.2",
    "astro": "^5.13.1",
    "astro-ai-robots-txt": "workspace:*",
    "sharp": "^0.33.5",
    "starlight-package-managers": "^0.10.0",
    "starlight-theme-flexoki": "^0.1.0"
  },
  "engines": {
    "node": "^18.17.1 || ^20.3.0 || >=21.0.0"
  },
  "private": true,
  "homepage": "https://delucis.github.io/astro-ai-robots-txt/",
  "repository": {
    "type": "git",
    "url": "https://github.com/delucis/astro-ai-robots-txt.git",
    "directory": "docs"
  },
  "bugs": "https://github.com/delucis/astro-ai-robots-txt/issues"
}
